{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA in Theano\n",
    "\n",
    "I'm following along with this tutorial: https://lazyprogrammer.me/principal-components-analysis-in-theano/\n",
    "\n",
    "In addition to helping me do the PSD analysis on the GPU, this will also give a gentle-ish intro to Theano...\n",
    "\n",
    "## Variables and functions in Theano:\n",
    "\n",
    "There's some weird allusions in the blog post to Theano all being based on Graph Theory, and how variables are nodes and equations are edges, or some such. Honestly I didn't follow, and I probably won't have to get into it in any case. In any case, conceptually it is just like thinking of Theano creating containers for variables and then defining function containers that operate on the variable containers to make new containers. The syntax seems simple enough once you see it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import pylearn2.models.pca\n",
    "import sklearn.decomposition.pca\n",
    "import torch\n",
    "\n",
    "X = T.matrix('X')\n",
    "Q = T.matrix('Q')\n",
    "Z = T.dot(X, Q)\n",
    "\n",
    "transform = theano.function(inputs=[X,Q], outputs=Z)\n",
    "\n",
    "X_val = np.random.randn(100,10).astype(np.float32)\n",
    "Q_val = np.random.randn(10,10).astype(np.float32)\n",
    "\n",
    "Z_val = transform(X_val, Q_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA theory is not explained well in this blog post.\n",
    "I'm going to black box it and if I feel the need, come back to it later..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.38270568])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xv_val = np.dot(X_val, init_v)\n",
    "np.dot(Xv_val.T, Xv_val)\n",
    "np.sum(evals[j]*np.dot(evecs[j], init_v)*np.dot(evecs[j], init_v) for j in range(len(init_v)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reshape{1}.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cost must be a scalar.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-7d0b1cefd68e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevecs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevecs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mgv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/lbignell/anaconda3/lib/python3.5/site-packages/theano/gradient.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(cost, wrt, consider_constant, disconnected_inputs, add_names, known_grads, return_disconnected, null_gradients)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcost\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cost must be a scalar.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cost must be a scalar."
     ]
    }
   ],
   "source": [
    "init_v = np.random.randn(10,1)\n",
    "v = theano.shared(init_v, name=\"v\")\n",
    "Xv = T.dot(X, v)\n",
    "evals = np.random.randn(10)\n",
    "evecs = np.random.randn(10,10)\n",
    "cost = T.dot(Xv.T, Xv) - np.sum(evals[j]*T.dot(evecs[j], v)*T.dot(evecs[j], v) for j in range(len(init_v)))\n",
    "\n",
    "gv = T.grad(cost.flatten(), v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, that doesn't seem to be working and his blog isn't detailed enough for me to figure it out. Time to move on to the official [Theano tutorial](http://deeplearning.net/software/theano/tutorial/index.html#tutorial)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0\n"
     ]
    }
   ],
   "source": [
    "#Adding two scalars:\n",
    "x = T.dscalar('x')\n",
    "y = T.dscalar('y')\n",
    "z = x + y\n",
    "f = theano.function([x,y], z)\n",
    "print(f(2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.   2.   4.]\n",
      " [  6.   8.  10.]]\n"
     ]
    }
   ],
   "source": [
    "#Adding two matrices:\n",
    "X = T.dmatrix('X')\n",
    "Y = T.dmatrix('Y')\n",
    "Z = X + Y\n",
    "F = theano.function([X,Y], Z)\n",
    "X_val = np.array([[0,1,2],[3,4,5]])\n",
    "Y_val = np.array([[0,1,2],[3,4,5]])\n",
    "print(F(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  3.  12.]\n"
     ]
    }
   ],
   "source": [
    "S = X.sum(axis=1)\n",
    "fs = theano.function([X], S)\n",
    "print(fs(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.5  3.5]\n"
     ]
    }
   ],
   "source": [
    "BG = X[:, 0:2].sum(axis=1)/2\n",
    "fbg = theano.function([X], BG)\n",
    "print(fbg(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 11.4 ms per loop\n"
     ]
    }
   ],
   "source": [
    "data = np.random.randn(10000, 1024).astype(np.float32)\n",
    "#Try in numpy, as fast as possible...\n",
    "%timeit data/(data[:, 40:].sum(axis=1) - data[:, 10:30].sum(axis=1)*((1024-40)/20))[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 22.3 ms per loop\n"
     ]
    }
   ],
   "source": [
    "X_norm = X/(X[:, 40:].sum(axis=1) - X[:, 10:30].sum(axis=1)*((1024-40)/20))[:, None]\n",
    "fnorm = theano.function([X], X_norm)\n",
    "%timeit fnorm(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret = fnorm(data)\n",
    "type(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 1.23 s per loop\n"
     ]
    }
   ],
   "source": [
    "#Try sklearn pca\n",
    "skpca = sklearn.decomposition.pca.PCA(n_components=10)\n",
    "%timeit skpca.fit(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 1.55 s per loop\n"
     ]
    }
   ],
   "source": [
    "#Try pylearn2 pca\n",
    "plpca = pylearn2.models.pca.SVDPCA(num_components=10)\n",
    "%timeit plpca.train(ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: Theano uses the CPU for the SVD!\n",
    "\n",
    "skcuda can access the cusolver library, which does SVD on the GPU. I haven't been able to get the GPU to speed up the execution (to faster than numpy) using this approach, and have run into memory errors. In principle, it should be able to run faster, but I can't figure out why (I need to spend more time learning the basics)... For now I'll abandon this and use sklearn (which uses numpy).\n",
    "\n",
    "Aside: the main processing part of doing PCA is SVD. With SVD it takes some matrix $A$ and return three matrices: [eigenvectors of $AA^{T}$ as columns] [sqrt of eigenvalues on diagonal (descending)] [eigenvectors of $A^{T}A$ as columns]. Subtracting the mean values of the waveforms means that $A^{T}A$ is just the covariance matrix, and so SVD gives us our PCA eigenvectors and eigenvalues in one step!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
